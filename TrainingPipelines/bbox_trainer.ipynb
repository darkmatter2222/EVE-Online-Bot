{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ee72090-6d81-4b7c-9123-36e89fc65a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os, decimal, json\n",
    "sys.path.append(os.path.realpath('..'))\n",
    "import json, time\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL, json\n",
    "import tensorflow as tf\n",
    "import socket\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from TrainingPipelines.ImageClassifier.ModelBuilder import build_and_train\n",
    "\n",
    "import seaborn as sns\n",
    "import mplcyberpunk\n",
    "\n",
    "plt.style.use(\"cyberpunk\")\n",
    "plt.rcParams['figure.facecolor'] = '#0d1117'\n",
    "plt.rcParams['axes.facecolor'] = '#0d1117'\n",
    "plt.rcParams['savefig.facecolor'] = '#0d1117'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df843d48-b2c9-48d2-8aa9-ca485a1798de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17bd6193-a673-49a6-95ba-b4dc483b6a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal_iou(y_true, y_pred):\n",
    "    x1 = max(y_true[0], y_pred[0])\n",
    "    y1 = max(y_true[1], y_pred[1])\n",
    "    x2 = min(y_true[2], y_pred[2])\n",
    "    y2 = min(y_true[3], y_pred[3])\n",
    " \n",
    "    intersection_area = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n",
    " \n",
    "    true_area = (y_true[2] - y_true[0] + 1) * (y_true[3] - y_true[1] + 1)\n",
    "    bbox_area = (y_pred[2] - y_pred[0] + 1) * (y_pred[3] - y_pred[1] + 1)\n",
    " \n",
    "    iou = intersection_area / float(true_area + bbox_area - intersection_area)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7efbfef4-2e46-4fdc-abe8-e5020097fd8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reduction = 4\n",
    "\n",
    "img_width = int(1920/reduction)\n",
    "img_height = int(1080/reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8e86c7b-3654-4f73-a185-85c888cf56fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_names = []\n",
    "path = pathlib.Path('O:\\\\source\\\\repos\\\\data_labeler\\\\training_data\\\\\\inventory')\n",
    "for data in glob.glob(f\"{path}\\*.png\"):\n",
    "    file = data.split('\\\\')[-1:][0]\n",
    "    image_names.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f57c3118-a407-4440-95a8-f1d655ca3f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.shuffle(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d3d091b-f5f6-42ea-8b81-abe09808adfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[783, 430, 1333, 725]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data = {}\n",
    "f = open(f\"{path}\\\\boxes.json\")\n",
    "image_data_raw = json.load(f)\n",
    "f.close()\n",
    "\n",
    "for data in image_data_raw:\n",
    "    image_data[data['image_name']] = data['bbox']\n",
    "image_data[list(image_data.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdb7d794-c9de-40ff-b645-05403b822ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key in image_data:\n",
    "    if image_data[key][0] > image_data[key][2]:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e7b0e19-6c00-4298-b3a5-ef9a3bac6e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_names, val_names, test_names = np.split(image_names, [int(len(image_names)*0.8), int(len(image_names)*0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa32e3b2-0e19-4c92-8aa9-1eff5b0794c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 775/775 [00:29<00:00, 26.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 97/97 [00:03<00:00, 26.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 97/97 [00:03<00:00, 26.03it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "for image_name in tqdm(train_names):\n",
    "    try:\n",
    "        img = Image.open(f\"{path}\\\\{image_name}\")\n",
    "        if reduction != 1:\n",
    "            img = img.resize((img_width, img_height), resample=Image.Resampling.LANCZOS)\n",
    "        train_x.append(np.array(img))\n",
    "    except:\n",
    "        print(f\"{path}\\\\{image_name}\")\n",
    "    \n",
    "val_x = []\n",
    "for image_name in tqdm(val_names):\n",
    "    img = Image.open(f\"{path}\\\\{image_name}\")\n",
    "    if reduction != 1:\n",
    "        img = img.resize((img_width, img_height), resample=Image.Resampling.LANCZOS)\n",
    "    val_x.append(np.array(img))\n",
    "    \n",
    "test_x = []\n",
    "for image_name in tqdm(test_names):\n",
    "    img = Image.open(f\"{path}\\\\{image_name}\")\n",
    "    if reduction != 1:\n",
    "        img = img.resize((img_width, img_height), resample=Image.Resampling.LANCZOS)\n",
    "    test_x.append(np.array(img))\n",
    "    \n",
    "train_x = np.array(train_x)\n",
    "val_x = np.array(val_x)\n",
    "test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a80ef4e4-9435-4704-b9bb-d5956161e2f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 480, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7fa3b9ef-e7f1-43c5-93cc-4bae66346d96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 775/775 [00:00<00:00, 777094.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 97/97 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 97/97 [00:00<00:00, 97076.47it/s]\n"
     ]
    }
   ],
   "source": [
    "train_y = []\n",
    "for image_name in tqdm(train_names):\n",
    "    train_y.append(image_data[image_name])\n",
    "    \n",
    "val_y = []\n",
    "for image_name in tqdm(val_names):\n",
    "    val_y.append(image_data[image_name])\n",
    "    \n",
    "test_y = []\n",
    "for image_name in tqdm(test_names):\n",
    "    test_y.append(image_data[image_name])\n",
    "\n",
    "train_y = np.array(train_y) / np.array([1920, 1080, 1920, 1080])\n",
    "val_y = np.array(val_y) / np.array([1920, 1080, 1920, 1080])\n",
    "test_y = np.array(test_y) / np.array([1920, 1080, 1920, 1080])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "455a7f9f-108f-47ed-bbee-335afd537618",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'674d07db-cbed-11ed-8167-2cf05d9fe8eb.png'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51a56a17-e3a5-49d2-a3b5-3c8600f513c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3296875 , 0.15185185, 0.640625  , 0.47407407])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0756c4c6-e442-40b1-8c29-783f3789eeef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vgg = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=(img_height, img_width, 3))\n",
    "vgg.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "620ae025-ad6b-4a9d-9400-1b4b42e6af82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Rescaling(1. / 255, input_shape=(img_height, img_width, 3)),\n",
    "    #layers.Resizing(img_height, img_width, interpolation='bilinear', crop_to_aspect_ratio=False),\n",
    "    #layers.Normalization(input_shape=(img_height, img_width, 3)),\n",
    "    #vgg,\n",
    "    #layers.GlobalAveragePooling2D(),\n",
    "    layers.Conv2D(16, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(256, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(512, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(4, activation=\"sigmoid\")    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eab4c92d-f4fd-4673-a25a-62f06ff575ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_5 (Rescaling)     (None, 270, 480, 3)       0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 268, 478, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 134, 239, 16)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 132, 237, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 66, 118, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 64, 116, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 32, 58, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 30, 56, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 15, 28, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 13, 26, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 6, 13, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 4, 11, 512)        1180160   \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 2, 5, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 5120)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               1310976   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,884,772\n",
      "Trainable params: 2,884,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f67e9aaa-7261-4e6d-bb1d-9bf93bbed0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_iou(y_true, y_pred):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "    Keras provides the input as numpy arrays with shape (batch_size, num_columns).\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- first box, numpy array with format [x, y, width, height, conf_score]\n",
    "    y_pred -- second box, numpy array with format [x, y, width, height, conf_score]\n",
    "    x any y are the coordinates of the top left corner of each box.\n",
    "    \n",
    "    Output: IoU of type float32. (This is a ratio. Max is 1. Min is 0.)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(0,y_true.shape[0]):\n",
    "    \n",
    "        # set the types so we are sure what type we are using\n",
    "        y_true = y_true.astype(np.float32)\n",
    "        y_pred = y_pred.astype(np.float32)\n",
    "\n",
    "\n",
    "        # boxTrue\n",
    "        x_boxTrue_tleft = y_true[0,0]  # numpy index selection\n",
    "        y_boxTrue_tleft = y_true[0,1]\n",
    "        boxTrue_width = y_true[0,2]\n",
    "        boxTrue_height = y_true[0,3]\n",
    "        area_boxTrue = (boxTrue_width * boxTrue_height)\n",
    "\n",
    "        # boxPred\n",
    "        x_boxPred_tleft = y_pred[0,0]\n",
    "        y_boxPred_tleft = y_pred[0,1]\n",
    "        boxPred_width = y_pred[0,2]\n",
    "        boxPred_height = y_pred[0,3]\n",
    "        area_boxPred = (boxPred_width * boxPred_height)\n",
    "\n",
    "\n",
    "        # calculate the bottom right coordinates for boxTrue and boxPred\n",
    "\n",
    "        # boxTrue\n",
    "        x_boxTrue_br = x_boxTrue_tleft + boxTrue_width\n",
    "        y_boxTrue_br = y_boxTrue_tleft + boxTrue_height # Version 2 revision\n",
    "\n",
    "        # boxPred\n",
    "        x_boxPred_br = x_boxPred_tleft + boxPred_width\n",
    "        y_boxPred_br = y_boxPred_tleft + boxPred_height # Version 2 revision\n",
    "\n",
    "\n",
    "        # calculate the top left and bottom right coordinates for the intersection box, boxInt\n",
    "\n",
    "        # boxInt - top left coords\n",
    "        x_boxInt_tleft = np.max([x_boxTrue_tleft,x_boxPred_tleft])\n",
    "        y_boxInt_tleft = np.max([y_boxTrue_tleft,y_boxPred_tleft]) # Version 2 revision\n",
    "\n",
    "        # boxInt - bottom right coords\n",
    "        x_boxInt_br = np.min([x_boxTrue_br,x_boxPred_br])\n",
    "        y_boxInt_br = np.min([y_boxTrue_br,y_boxPred_br]) \n",
    "\n",
    "        # Calculate the area of boxInt, i.e. the area of the intersection \n",
    "        # between boxTrue and boxPred.\n",
    "        # The np.max() function forces the intersection area to 0 if the boxes don't overlap.\n",
    "        \n",
    "        \n",
    "        # Version 2 revision\n",
    "        area_of_intersection = \\\n",
    "        np.max([0,(x_boxInt_br - x_boxInt_tleft)]) * np.max([0,(y_boxInt_br - y_boxInt_tleft)])\n",
    "\n",
    "        iou = area_of_intersection / ((area_boxTrue + area_boxPred) - area_of_intersection)\n",
    "\n",
    "\n",
    "        # This must match the type used in py_func\n",
    "        iou = iou.astype(np.float32)\n",
    "        \n",
    "        # append the result to a list at the end of each loop\n",
    "        results.append(iou)\n",
    "    \n",
    "    # return the mean IoU score for the batch\n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c6f1ba0d-dead-4133-8600-5d139f4f3d34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def IoU(y_true, y_pred):\n",
    "    \n",
    "    # Note: the type float32 is very important. It must be the same type as the output from\n",
    "    # the python function above or you too may spend many late night hours \n",
    "    # trying to debug and almost give up.\n",
    "    \n",
    "    iou = tf.numpy_function(calculate_iou, [y_true, y_pred], tf.float32)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5276ea0a-3492-4af0-b0ac-a000b8a7b768",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 13s 521ms/step - loss: 0.0578 - accuracy: 0.4748 - mse: 0.0578 - IoU: 0.2182 - val_loss: 0.0475 - val_accuracy: 0.5052 - val_mse: 0.0475 - val_IoU: 0.3734 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 12s 472ms/step - loss: 0.0469 - accuracy: 0.5884 - mse: 0.0469 - IoU: 0.2848 - val_loss: 0.0448 - val_accuracy: 0.4536 - val_mse: 0.0448 - val_IoU: 0.3846 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 12s 475ms/step - loss: 0.0389 - accuracy: 0.6361 - mse: 0.0389 - IoU: 0.2532 - val_loss: 0.0330 - val_accuracy: 0.7113 - val_mse: 0.0330 - val_IoU: 0.4845 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 12s 473ms/step - loss: 0.0229 - accuracy: 0.7329 - mse: 0.0229 - IoU: 0.3920 - val_loss: 0.0204 - val_accuracy: 0.7629 - val_mse: 0.0204 - val_IoU: 0.6711 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 12s 471ms/step - loss: 0.0139 - accuracy: 0.8387 - mse: 0.0139 - IoU: 0.5537 - val_loss: 0.0125 - val_accuracy: 0.7938 - val_mse: 0.0125 - val_IoU: 0.7133 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 12s 473ms/step - loss: 0.0080 - accuracy: 0.8542 - mse: 0.0080 - IoU: 0.6801 - val_loss: 0.0081 - val_accuracy: 0.7835 - val_mse: 0.0081 - val_IoU: 0.7095 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 12s 471ms/step - loss: 0.0056 - accuracy: 0.8477 - mse: 0.0056 - IoU: 0.6887 - val_loss: 0.0053 - val_accuracy: 0.8041 - val_mse: 0.0053 - val_IoU: 0.7918 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 12s 478ms/step - loss: 0.0041 - accuracy: 0.8632 - mse: 0.0041 - IoU: 0.7931 - val_loss: 0.0043 - val_accuracy: 0.7938 - val_mse: 0.0043 - val_IoU: 0.7897 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 12s 475ms/step - loss: 0.0032 - accuracy: 0.8542 - mse: 0.0032 - IoU: 0.7970 - val_loss: 0.0037 - val_accuracy: 0.8247 - val_mse: 0.0037 - val_IoU: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 12s 476ms/step - loss: 0.0027 - accuracy: 0.8813 - mse: 0.0027 - IoU: 0.7996 - val_loss: 0.0032 - val_accuracy: 0.8041 - val_mse: 0.0032 - val_IoU: 0.7673 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 12s 477ms/step - loss: 0.0022 - accuracy: 0.8839 - mse: 0.0022 - IoU: 0.7814 - val_loss: 0.0029 - val_accuracy: 0.8144 - val_mse: 0.0029 - val_IoU: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 12s 477ms/step - loss: 0.0019 - accuracy: 0.8787 - mse: 0.0019 - IoU: 0.7952 - val_loss: 0.0024 - val_accuracy: 0.8144 - val_mse: 0.0024 - val_IoU: 0.7951 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 12s 478ms/step - loss: 0.0015 - accuracy: 0.8981 - mse: 0.0015 - IoU: 0.8159 - val_loss: 0.0021 - val_accuracy: 0.8144 - val_mse: 0.0021 - val_IoU: 0.8236 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 12s 478ms/step - loss: 0.0013 - accuracy: 0.8994 - mse: 0.0013 - IoU: 0.8378 - val_loss: 0.0018 - val_accuracy: 0.8144 - val_mse: 0.0018 - val_IoU: 0.8389 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 12s 477ms/step - loss: 0.0011 - accuracy: 0.9045 - mse: 0.0011 - IoU: 0.8363 - val_loss: 0.0017 - val_accuracy: 0.8144 - val_mse: 0.0017 - val_IoU: 0.8480 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 12s 477ms/step - loss: 9.8029e-04 - accuracy: 0.9071 - mse: 9.8029e-04 - IoU: 0.8600 - val_loss: 0.0016 - val_accuracy: 0.8247 - val_mse: 0.0016 - val_IoU: 0.8180 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 12s 478ms/step - loss: 8.9181e-04 - accuracy: 0.9058 - mse: 8.9181e-04 - IoU: 0.8478 - val_loss: 0.0014 - val_accuracy: 0.8454 - val_mse: 0.0014 - val_IoU: 0.8102 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 12s 484ms/step - loss: 8.0158e-04 - accuracy: 0.9045 - mse: 8.0158e-04 - IoU: 0.8676 - val_loss: 0.0014 - val_accuracy: 0.8660 - val_mse: 0.0014 - val_IoU: 0.8274 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 12s 477ms/step - loss: 7.4052e-04 - accuracy: 0.9097 - mse: 7.4052e-04 - IoU: 0.8907 - val_loss: 0.0015 - val_accuracy: 0.8866 - val_mse: 0.0015 - val_IoU: 0.8019 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 12s 496ms/step - loss: 7.5470e-04 - accuracy: 0.9187 - mse: 7.5470e-04 - IoU: 0.8614 - val_loss: 0.0011 - val_accuracy: 0.8969 - val_mse: 0.0011 - val_IoU: 0.8395 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 12s 482ms/step - loss: 5.6292e-04 - accuracy: 0.9329 - mse: 5.6292e-04 - IoU: 0.9084 - val_loss: 9.5453e-04 - val_accuracy: 0.8866 - val_mse: 9.5453e-04 - val_IoU: 0.8737 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 4.8110e-04 - accuracy: 0.9213 - mse: 4.8110e-04 - IoU: 0.9103 - val_loss: 0.0013 - val_accuracy: 0.8247 - val_mse: 0.0013 - val_IoU: 0.8396 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 12s 485ms/step - loss: 4.9354e-04 - accuracy: 0.9252 - mse: 4.9354e-04 - IoU: 0.8904 - val_loss: 9.5388e-04 - val_accuracy: 0.8969 - val_mse: 9.5388e-04 - val_IoU: 0.8593 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 12s 482ms/step - loss: 4.7411e-04 - accuracy: 0.9290 - mse: 4.7411e-04 - IoU: 0.8861 - val_loss: 8.9189e-04 - val_accuracy: 0.9175 - val_mse: 8.9189e-04 - val_IoU: 0.8820 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 12s 481ms/step - loss: 3.8677e-04 - accuracy: 0.9355 - mse: 3.8677e-04 - IoU: 0.9086 - val_loss: 9.4294e-04 - val_accuracy: 0.8763 - val_mse: 9.4294e-04 - val_IoU: 0.9111 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 3.8484e-04 - accuracy: 0.9471 - mse: 3.8484e-04 - IoU: 0.9015 - val_loss: 8.1697e-04 - val_accuracy: 0.8866 - val_mse: 8.1697e-04 - val_IoU: 0.8710 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 12s 482ms/step - loss: 3.2256e-04 - accuracy: 0.9458 - mse: 3.2256e-04 - IoU: 0.8762 - val_loss: 8.5077e-04 - val_accuracy: 0.9072 - val_mse: 8.5077e-04 - val_IoU: 0.8890 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 12s 482ms/step - loss: 2.8917e-04 - accuracy: 0.9535 - mse: 2.8917e-04 - IoU: 0.9031 - val_loss: 7.8722e-04 - val_accuracy: 0.8969 - val_mse: 7.8722e-04 - val_IoU: 0.8686 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 2.8834e-04 - accuracy: 0.9535 - mse: 2.8834e-04 - IoU: 0.9217 - val_loss: 7.7092e-04 - val_accuracy: 0.8763 - val_mse: 7.7092e-04 - val_IoU: 0.9146 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 2.7056e-04 - accuracy: 0.9471 - mse: 2.7056e-04 - IoU: 0.9227 - val_loss: 7.6998e-04 - val_accuracy: 0.8866 - val_mse: 7.6998e-04 - val_IoU: 0.8925 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - ETA: 0s - loss: 2.6833e-04 - accuracy: 0.9471 - mse: 2.6833e-04 - IoU: 0.9222\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "25/25 [==============================] - 12s 484ms/step - loss: 2.6833e-04 - accuracy: 0.9471 - mse: 2.6833e-04 - IoU: 0.9222 - val_loss: 7.7003e-04 - val_accuracy: 0.8969 - val_mse: 7.7003e-04 - val_IoU: 0.8963 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 12s 484ms/step - loss: 2.2192e-04 - accuracy: 0.9484 - mse: 2.2192e-04 - IoU: 0.9285 - val_loss: 6.5413e-04 - val_accuracy: 0.9072 - val_mse: 6.5413e-04 - val_IoU: 0.9161 - lr: 1.0000e-06\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 12s 487ms/step - loss: 1.8650e-04 - accuracy: 0.9458 - mse: 1.8650e-04 - IoU: 0.9390 - val_loss: 6.5016e-04 - val_accuracy: 0.9072 - val_mse: 6.5016e-04 - val_IoU: 0.9205 - lr: 1.0000e-06\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 1.7958e-04 - accuracy: 0.9471 - mse: 1.7958e-04 - IoU: 0.9328 - val_loss: 6.5303e-04 - val_accuracy: 0.9072 - val_mse: 6.5303e-04 - val_IoU: 0.9215 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 12s 486ms/step - loss: 1.7602e-04 - accuracy: 0.9471 - mse: 1.7602e-04 - IoU: 0.9238 - val_loss: 6.5234e-04 - val_accuracy: 0.9072 - val_mse: 6.5234e-04 - val_IoU: 0.9221 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 12s 484ms/step - loss: 1.7345e-04 - accuracy: 0.9471 - mse: 1.7345e-04 - IoU: 0.9418 - val_loss: 6.5243e-04 - val_accuracy: 0.9072 - val_mse: 6.5243e-04 - val_IoU: 0.9229 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.7149e-04 - accuracy: 0.9484 - mse: 1.7149e-04 - IoU: 0.9345\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "25/25 [==============================] - 12s 485ms/step - loss: 1.7149e-04 - accuracy: 0.9484 - mse: 1.7149e-04 - IoU: 0.9345 - val_loss: 6.5283e-04 - val_accuracy: 0.9072 - val_mse: 6.5283e-04 - val_IoU: 0.9241 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 12s 496ms/step - loss: 1.6996e-04 - accuracy: 0.9497 - mse: 1.6996e-04 - IoU: 0.9225 - val_loss: 6.5275e-04 - val_accuracy: 0.9072 - val_mse: 6.5275e-04 - val_IoU: 0.9241 - lr: 1.0000e-07\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 12s 486ms/step - loss: 1.6981e-04 - accuracy: 0.9497 - mse: 1.6981e-04 - IoU: 0.9427 - val_loss: 6.5234e-04 - val_accuracy: 0.9072 - val_mse: 6.5234e-04 - val_IoU: 0.9242 - lr: 1.0000e-07\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 12s 485ms/step - loss: 1.6967e-04 - accuracy: 0.9497 - mse: 1.6967e-04 - IoU: 0.9269 - val_loss: 6.5234e-04 - val_accuracy: 0.9072 - val_mse: 6.5234e-04 - val_IoU: 0.9240 - lr: 1.0000e-07\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 12s 484ms/step - loss: 1.6947e-04 - accuracy: 0.9497 - mse: 1.6947e-04 - IoU: 0.9267 - val_loss: 6.5215e-04 - val_accuracy: 0.9072 - val_mse: 6.5215e-04 - val_IoU: 0.9241 - lr: 1.0000e-07\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 1.6929e-04 - accuracy: 0.9510 - mse: 1.6929e-04 - IoU: 0.9275 - val_loss: 6.5216e-04 - val_accuracy: 0.9072 - val_mse: 6.5216e-04 - val_IoU: 0.9243 - lr: 1.0000e-07\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 12s 486ms/step - loss: 1.6915e-04 - accuracy: 0.9510 - mse: 1.6915e-04 - IoU: 0.9534 - val_loss: 6.5210e-04 - val_accuracy: 0.9072 - val_mse: 6.5210e-04 - val_IoU: 0.9242 - lr: 1.0000e-07\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 12s 484ms/step - loss: 1.6898e-04 - accuracy: 0.9510 - mse: 1.6898e-04 - IoU: 0.9397 - val_loss: 6.5229e-04 - val_accuracy: 0.9072 - val_mse: 6.5229e-04 - val_IoU: 0.9242 - lr: 1.0000e-07\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 12s 486ms/step - loss: 1.6881e-04 - accuracy: 0.9510 - mse: 1.6881e-04 - IoU: 0.9433 - val_loss: 6.5202e-04 - val_accuracy: 0.9072 - val_mse: 6.5202e-04 - val_IoU: 0.9243 - lr: 1.0000e-07\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 12s 486ms/step - loss: 1.6865e-04 - accuracy: 0.9510 - mse: 1.6865e-04 - IoU: 0.9459 - val_loss: 6.5178e-04 - val_accuracy: 0.9072 - val_mse: 6.5178e-04 - val_IoU: 0.9242 - lr: 1.0000e-07\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 12s 494ms/step - loss: 1.6850e-04 - accuracy: 0.9510 - mse: 1.6850e-04 - IoU: 0.9527 - val_loss: 6.5171e-04 - val_accuracy: 0.9072 - val_mse: 6.5171e-04 - val_IoU: 0.9245 - lr: 1.0000e-07\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 12s 487ms/step - loss: 1.6833e-04 - accuracy: 0.9523 - mse: 1.6833e-04 - IoU: 0.9578 - val_loss: 6.5168e-04 - val_accuracy: 0.9072 - val_mse: 6.5168e-04 - val_IoU: 0.9244 - lr: 1.0000e-07\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 12s 485ms/step - loss: 1.6818e-04 - accuracy: 0.9510 - mse: 1.6818e-04 - IoU: 0.9442 - val_loss: 6.5187e-04 - val_accuracy: 0.9072 - val_mse: 6.5187e-04 - val_IoU: 0.9244 - lr: 1.0000e-07\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 12s 485ms/step - loss: 1.6802e-04 - accuracy: 0.9510 - mse: 1.6802e-04 - IoU: 0.9360 - val_loss: 6.5178e-04 - val_accuracy: 0.9175 - val_mse: 6.5178e-04 - val_IoU: 0.9245 - lr: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "lr = 1e-4\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5, min_lr=1e-7, verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
    "]\n",
    "\n",
    "IOUL = tfa.losses.GIoULoss(\n",
    "    mode='giou',\n",
    "    reduction=tf.keras.losses.Reduction.AUTO,\n",
    "    name='giou_loss'\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(lr), loss='mse', metrics=['accuracy', 'mse', IoU])\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    validation_data=(val_x, val_y),\n",
    "    batch_size=32,\n",
    "    #shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "30b0a7cc-f899-4fd6-88e0-67ad6f86f847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cell_dims(x1, y1, x2, y2):\n",
    "    return x1, y1, (x2 - x1) + x1, (y2 - y1) + y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bcd9c5cc-c14c-4efe-aa7c-f90de1dc1ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 150ms/step\n",
      "Average IOU for Test:0.9511159803882773\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_x)\n",
    "IOUs = []\n",
    "for i in range(len(test_y)):\n",
    "    IOUs.append(cal_iou(prediction[i], test_y[i]))\n",
    "print(f'Average IOU for Test:{sum(IOUs)/len(IOUs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "953a4ba0-e9b3-460d-b0ee-6776cb2005c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91944885"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_iou(test_y, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fde2135e-52fb-4ea4-9099-aba933de4b39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4828125 , 0.02592593, 0.99791667, 0.61666667])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c006226-436d-4d4e-99a3-9850c02f8db1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47408763, 0.02822068, 0.9477787 , 0.6214723 ], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4624047-2d8b-4af1-a157-a3c1c44474da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_image_index = 0\n",
    "\n",
    "prediction = model.predict(np.array([test_x[test_image_index]]))\n",
    "result = ((prediction) * np.array([1920, 1080, 1920, 1080])) # reduction\n",
    "print(result)\n",
    "truth = (test_y[test_image_index] * np.array([1920, 1080, 1920, 1080])) # reduction\n",
    "print(truth)\n",
    "\n",
    "print(f'IOU:{cal_iou(prediction[0], test_y[test_image_index])}')\n",
    "\n",
    "#mg = Image.fromarray(test_x[test_image_index]) \n",
    "img = Image.open(f\"{path}\\\\{test_names[test_image_index]}\")\n",
    "img1 = ImageDraw.Draw(img)  \n",
    "result2 = cell_dims(*result[0])\n",
    "print(result2)\n",
    "img1.rectangle([(result2[0], result2[1]), (result2[2], result2[3])], outline =\"red\")\n",
    "\n",
    "result3 = cell_dims(*truth)\n",
    "img1.rectangle([(result3[0], result3[1]), (result3[2], result3[3])], outline =\"Green\")\n",
    "\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ff6ab3e7-7395-4da2-89d9-8b5ba9e3ade2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('temp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "503b6a0c-4894-4eae-a380-52923c527271",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "IoU.__init__() missing 2 required positional arguments: 'num_classes' and 'target_class_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model2 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model2\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([test_x[test_image_index]]))\n",
      "File \u001b[1;32mO:\\source\\repos\\venv\\Python310GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mO:\\source\\repos\\venv\\Python310GPU\\lib\\site-packages\\keras\\dtensor\\utils.py:144\u001b[0m, in \u001b[0;36minject_mesh.<locals>._wrap_function\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mesh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     instance\u001b[38;5;241m.\u001b[39m_mesh \u001b[38;5;241m=\u001b[39m mesh\n\u001b[1;32m--> 144\u001b[0m init_method(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: IoU.__init__() missing 2 required positional arguments: 'num_classes' and 'target_class_ids'"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.load_model('temp.h5')\n",
    "model2.predict(np.array([test_x[test_image_index]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9fda4-8ec1-4e37-bf08-fd8d46576d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8457486d-52a1-4f3e-85b3-5e7278e3c394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e53df-b928-4c2a-b288-bf72208417e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d430df-93e6-41a1-ab37-b8f4fb81f59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d87e27-21c9-4d96-9ec5-dac14245f5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
