{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec0268dc-7161-41c0-b68f-c221910ee358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os, decimal, json\n",
    "sys.path.append(os.path.realpath('..'))\n",
    "import json, time\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL, json\n",
    "import tensorflow as tf\n",
    "import socket\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from TrainingPipelines.ImageClassifier.ModelBuilder import build_and_train\n",
    "\n",
    "import seaborn as sns\n",
    "import mplcyberpunk\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "plt.style.use(\"cyberpunk\")\n",
    "plt.rcParams['figure.facecolor'] = '#0d1117'\n",
    "plt.rcParams['axes.facecolor'] = '#0d1117'\n",
    "plt.rcParams['savefig.facecolor'] = '#0d1117'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291b230a-0f31-47bf-b0ba-bca10e427a18",
   "metadata": {},
   "source": [
    "# PLAN\n",
    "1. Train Boxes\n",
    "2. transfer in those boxes\n",
    "3. train location of boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b37154af-c56d-4656-a3b2-b3c8d12b6fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_meta = {'image_resize': [20, 8],\n",
    "     'class_location': 'O:\\\\eve_models\\\\training_data\\\\box_counter\\\\box_counter_classes.json',\n",
    "     'model_location': 'O:\\\\eve_models\\\\training_data\\\\box_counter\\\\box_counter_model.h5',\n",
    "     'class_names': ['1', '2'],\n",
    "     'cm': [[ 70,   0],\n",
    "            [  0, 115]]}\n",
    "box_counter_model = tf.keras.models.load_model(config_meta['model_location'], compile=False)\n",
    "config = json.load(open(config_meta['class_location']))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d0b83e7-2513-4889-9b8f-0d92fcaac8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.preprocessing.image_preprocessing.Rescaling at 0x1323bc19870>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1323bc19f30>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1323bc1b430>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1323bc4c8e0>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1323bc4d7b0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1323bc4e500>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1323bc4e260>,\n",
       " <keras.layers.reshaping.flatten.Flatten at 0x1323bc4e1a0>,\n",
       " <keras.layers.core.dense.Dense at 0x1323bc4f040>,\n",
       " <keras.layers.regularization.dropout.Dropout at 0x1323bc4f880>,\n",
       " <keras.layers.core.dense.Dense at 0x1323bc4f5b0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_counter_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3090082d-4f1d-4f84-bd81-a972c9f4f30c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = Image.open(r\"O:\\eve_models\\training_data\\box_counter\\2\\0a560779-d4cf-11ed-bc5e-2cf05d9fe8eb.png\")\n",
    "train_x = []\n",
    "\n",
    "img = img.resize(\n",
    "    (config_meta['image_resize'][1], config_meta['image_resize'][0]),\n",
    "    # TF trains backwards\n",
    "    resample=Image.Resampling.NEAREST)\n",
    "\n",
    "train_x.append(np.array(img))\n",
    "\n",
    "image_array = train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77052ddc-376e-4298-bd6f-4f70eebbbd87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 8, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "423eae9d-ddb2-4819-b17b-7799ae16da52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-11.821878,  15.709077]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = box_counter_model.predict(np.array([image_array]))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfdc3b25-1f06-491e-8e6d-e24d50c6b761",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAAgAAAAUCAIAAAA/ees8AAAA2klEQVR4nF2QMU5DMRBE36w3RIpoUyJFSBFUuQIlN8hVcoZchUNwBppIuQFUVPBpiJdi7f9/sGR51p4d74zuN3eIYfgBFARtGUog0HSAd9CoY4ejWaXeD25QJTOrETfL5aKYUIBjKtLqdnX5vZRiknIKR627eIFJ0/P68bAHzseXh8MeeD/tPBnrp10+JPiszx4g+Hh9S0aC4VS13W7+OSAQGAhNtmefi2jW2qAoWiQS319Dl4keCRBGT2YMxQCoELNkASym8AMYB/HWEZ0bueUzwSszdqWssYg/VV48E+GI1JsAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=8x20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2d64fba-c2ea-4c63-9a17-55531fbbe61d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc090611-6e43-4792-ae27-be137e6fb08e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv_model = tf.keras.Model(box_counter_model.layers[0:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86d4e4f2-3df9-4908-a142-3396adb64b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001356EBC8A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013513C2F9A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "layer_outputs = []\n",
    "for i in range(1, len(box_counter_model.layers)):\n",
    "    tmp_model = tf.keras.Model(box_counter_model.layers[0].input, box_counter_model.layers[i].output)\n",
    "    tmp_output = tmp_model.predict(np.array([image_array]))[0]\n",
    "    layer_outputs.append(tmp_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e82609ed-0dc1-4ff1-917d-8202f57d31c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2, 32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_outputs[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "753d9bba-6ff2-4b77-a287-bd2d046907c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_outputs[3][:,:,0:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6bd62f07-8133-4224-9ec6-18ed5160b63d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 8, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single = layer_outputs[0][:,:,0:3]\n",
    "single = (single * np.array(1000)).astype(np.uint8)\n",
    "single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c30a7cff-c363-4f0f-a4fb-ebc2194db07d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAAgAAAAUCAIAAAA/ees8AAAA0klEQVR4nJXQu0oDcRDF4e+/7m5kwWCpRYIXCFpp46URgqCFpbW1gr6EqIWND2AR38C8QAx4qX0PLSzEQg2atViLCFnRKQbm/M6cgVFXWvND1ajMHpWx30AYGEdIC2tE2uBCNgWfLWNr+t9R6xpXXo9o0vV8x3axdb/VWTDeNTnXul5U7ZzctMGyxxm7l5yuHk/Yaws7sg0s2T83XePQ7ZnZmoMHNrFCQuVnFxNI6JEQCMXhGHwQk4KcvAARPfD21yfm/wZhKIiNvqtGsr6XAfnJFw32KDBEzTUeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=8x20>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(single).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f390427-da9b-404f-a695-142deaf649f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.23544717, 0.        , 0.97299355, 0.11945027, 0.        ,\n",
       "       0.00321241, 0.        , 0.3977048 , 1.383597  , 0.        ,\n",
       "       0.        , 0.        , 0.92766416, 0.        , 1.0278487 ,\n",
       "       0.        , 0.        , 1.1910099 , 1.607712  , 0.        ,\n",
       "       0.        , 0.        , 1.5728966 , 0.        , 1.0251459 ,\n",
       "       0.41926244, 1.0394814 , 1.0289046 , 1.6481133 , 0.98409426,\n",
       "       0.        , 0.        , 0.24609137, 0.7172504 , 0.86423695,\n",
       "       0.        , 0.        , 1.6230892 , 0.        , 0.        ,\n",
       "       0.        , 0.31238276, 0.48728997, 0.        , 1.1716206 ,\n",
       "       0.        , 1.1728804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.0072582 , 0.37619072, 0.30103597, 0.37740222,\n",
       "       0.        , 1.1557908 , 0.        , 0.81128174, 0.        ,\n",
       "       1.4141653 , 0.71562594, 1.2477237 , 0.70214367, 0.5549363 ,\n",
       "       0.8446619 , 1.0294468 , 0.        , 0.33627737, 0.6627551 ,\n",
       "       0.5108382 , 0.10177048, 0.3363555 , 0.72705054, 0.        ,\n",
       "       0.2419451 , 0.11758809, 0.9978504 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.5159701 , 0.        , 0.5955473 ,\n",
       "       0.        , 1.150161  , 0.        , 0.        , 0.35905546,\n",
       "       0.        , 0.        , 0.09126873, 0.3487622 , 0.18617715,\n",
       "       0.        , 0.36022818, 0.72908837, 0.        , 0.4128102 ,\n",
       "       0.        , 1.8771207 , 0.28081033, 1.0286952 , 1.4784262 ,\n",
       "       0.4078564 , 0.44171065, 0.        , 0.        , 0.        ,\n",
       "       1.7291286 , 0.        , 0.47196698, 0.        , 0.5066899 ,\n",
       "       0.        , 0.01220423, 1.0966102 , 0.        , 0.        ,\n",
       "       0.        , 0.72157747, 0.        , 0.        , 0.6953329 ,\n",
       "       0.06092466, 1.5134252 , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_model = tf.keras.Model(box_counter_model.layers[0].input, box_counter_model.layers[7].output)\n",
    "for source_layer in source_model.layers:\n",
    "    source_model.trainable = False\n",
    "tmp_output = source_model.predict(np.array([image_array]))[0]\n",
    "tmp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55852d-4c5f-470f-b3bb-252d53f00f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f0d90-9ce4-4df4-a815-d5bdbbb369f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Input(shape=(img_height, img_width,3)),\n",
    "    #layers.Rescaling(1. / 255, input_shape=(img_height, img_width,3)),\n",
    "    source_model,\n",
    "    layers.Flatten(),\n",
    "    #layers.Dense(units=128, activation='relu'),\n",
    "    #layers.Dense(units=64, activation='relu'),\n",
    "    layers.Dense(units=32, activation=\"relu\"),\n",
    "    layers.Dense(units=1, activation=\"sigmoid\", name='bounding_box')  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be47bca-c6e4-4c14-9436-46ff46546270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f03870-96fc-4702-8667-d006bfc666ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b07d2-4f6a-4b81-ad6e-5530f5665528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
